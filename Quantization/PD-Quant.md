# PD-Quant: 基于预测差异度量的后训练量化

**出处会议：** CVPR 2023  
**是否开源：** https://github.com/hustvl/PD-Quant  
**关键词：** 训练后量化(PTQ)、预测差异度量、分布修正、全局感知

---

## 1. 概述

局部重建误差最小化 ≠ 全局任务损失最小化。

PD-Quant 提出从“局部特征相似”转向“全局预测一致”，通过引入预测差异度量和分布修正技术，显著提升了低比特量化的精度。

------

## 2. 方法

### 2.1 分布修正 (Distribution Correction, DC)

针对校准集样本（如 1024 张图）无法代表全局分布的问题，PD-Quant 利用预训练模型 BN 层中存储的全局统计量（Running Mean 和 Running Variance）作为“真值”，对输入特征图进行精修。

**优化目标：**

在量化当前块之前，保持权重固定，通过梯度下降优化该块的输入特征图 $A_{l-1}$ ：

$$
\min_{A_{l-1}^{DC}} \lambda_c \underbrace{\sum (||\hat{\mu}_{i,l} - \mu_{i,l}||_2^2 + ||\hat{\sigma}_{i,l} - \sigma_{i,l}||_2^2)}_{\text{第一项：分布对齐}} + \underbrace{||A_{l-1}^{DC} - A_{l-1}^{FP}||_2^2}_{\text{第二项：语义保持}}
$$

- **$\mu_{i,l}, \sigma_{i,l}$**：全精度模型 BN 层在海量训练集上积累的全局均值和方差。
- **$\hat{\mu}_{i,l}, \hat{\sigma}_{i,l}$**：当前校准批次经过该层后的实际统计量。
- **第一项（分布对齐）**：强制校准数据的分布向全局分布对齐。
- **第二项（语义保持）**：确保修正后的特征 $A_{l-1}^{DC}$ 依然保留原始图像的语义信息。

**结论**：DC 制造了一组更具代表性的“虚拟特征图”，为后续量化参数搜索提供了更准确的基准。

### 2.2 预测差异损失 (Prediction Difference Loss, PD)

为了让量化参数感知到对最终预测的影响，PD-Quant 将量化误差传播到最后一层。

**计算逻辑：**

1. 将修正后的特征 $A_{l-1}^{DC}$ 输入量化块。
2. 将该块的量化输出送入后续所有的**全精度层**。
3. 计算最终输出与原始全精度模型输出的 KL 散度。

**公式：**

$$
\mathcal{L}_{PD} = \sum KL(\text{Softmax}(O_{fp}) || \text{Softmax}(O_{pd}))
$$

这种方式不仅考虑了当前层的重建，还模拟了量化噪声对最终任务决策的影响。

### 2.3 带正则化的总损失函数

为了防止在极小校准集上产生过拟合，PD-Quant 引入了 MSE 正则化项，并结合权重舍入优化。

**总优化目标：**

$$
\arg \min_{\theta, S_a} \mathcal{L}_{PD}(O_{fp}, f_{l+1}(\overline{A}_l)) + \lambda_r ||A_l - \overline{A}_l||_2^2
$$

- **$\theta$**：权重的舍入参数（Rounding）。
- **$S_a$**：激活缩放因子（Scaling Factor）。
- **正则化项**：强制量化后的输出 $\overline{A}_l$ 在局部上也要接近全精度输出 $A_l$ 。

------

## 3. 算法执行流程 

1. **准备阶段**：加载预训练 FP32 模型，提取各 BN 层的全局统计量。
2. **分布修正阶段**：对于每一个 Block，通过梯度下降迭代优化输入激活值，得到 $A_{l-1}^{DC}$ 。
3. **参数初始化阶段**：利用 $A_{l-1}^{DC}$ ，通过 Min-Max 方案初步确定激活缩放因子 $S_a$ 。
4. **参数搜索阶段**：
   - 固定模型其他部分，仅针对当前块的 $\theta$ 和 $S_a$ 进行优化。
   - 计算总损失 $\mathcal{L}_{total} = \mathcal{L}_{PD} + \lambda_r \mathcal{L}_{reg}$ 。
   - 执行 20,000 次迭代更新参数。
5. **循环往复**：完成当前块量化，锁定参数，进入下一个 Block。

------

## 4. 实验结果与深度分析

### 4.1 激活缩放因子度量对比 (Table 1)

验证 PD 指标在寻找最优缩放因子时是否比传统指标更有效（ResNet-18 结果）。

| **Metric**    | **W8A2**   | **W4A2**   |
| ------------- | ---------- | ---------- |
| Min-Max       | 1.83%      | 0.81%      |
| Cosine        | 23.36%     | 15.68%     |
| MSE           | 23.15%     | 17.55%     |
| **PD (Ours)** | **28.41%** | **23.51%** |

- **分析**：在 2-bit 激活量化下，传统的局部度量（MSE/Cosine）几乎失效，而 PD 指标能准确捕获对精度贡献最大的激活范围。

### 4.2 消融实验：过拟合与正则化 (Table 2)

在 ResNet-18 (W2A2) 极端设置下验证各模块贡献。

| **Method**               | **Calibration Acc** | **Validation Acc** |
| ------------------------ | ------------------- | ------------------ |
| PD-only                  | 70.51%              | 1.07%              |
| PD + Reg                 | 51.56%              | 49.16%             |
| PD + Reg + Drop          | 53.07%              | 52.74%             |
| **PD + Reg + Drop + DC** | **53.33%**          | **53.14%**         |

- **分析**：仅使用 PD 损失会导致严重的过拟合（校准集高，验证集低）。正则化 (Reg) 是恢复精度的关键，而分布修正 (DC) 进一步缩小了泛化差距。

### 4.3 与 SOTA 方法对比 (Table 3)

在不同架构上对比当前顶尖的 PTQ 方法（精度数据）。

| **Model**       | **Bit (W/A)** | **BRECQ** | **QDrop** | **PD-Quant** |
| --------------- | ------------- | --------- | --------- | ------------ |
| **ResNet-18**   | 2/2           | 46.58%    | 51.42%    | **53.14%**   |
| **ResNet-50**   | 2/2           | 55.33%    | 61.94%    | **63.15%**   |
| **MobileNetV2** | 4/2           | 15.11%    | 17.30%    | **20.10%**   |
| **MNasNet**     | 2/2           | 20.33%    | 23.59%    | **27.58%**   |

- **分析**：PD-Quant 在所有低比特设置下均优于基准。特别是在 MobileNet 和 MNasNet 等紧凑型网络上，由于其对分布更敏感，PD-Quant 带来的增益更加显著（最高提升 4%）。

------

## 5. 总结

PD-Quant 的核心逻辑推导：

1. **数据层面**：利用 BN 统计量通过 DC 修正校准集特征，提供更稳健的优化起点。
2. **指标层面**：利用 PD 损失将优化目标与最终任务表现挂钩，解决了局部 MSE 的偏差问题。
3. **优化层面**：通过正则化与 Random Drop 抑制小样本过拟合，保证了模型在 2-bit 极低比特下的泛化性能。
