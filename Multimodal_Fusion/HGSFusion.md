# HGSFusion 学习笔记：带混合生成与同步的雷达-相机融合 3D 目标检测

**出处会议：** AAAI 2025  
**是否开源：** https://github.com/garfield-cpp/HGSFusion  
**关键词：** 4D毫米波雷达-相机融合、点云生成、深度同步、混合概率分布

---

## 1. 概述

HGSFusion 是一种专门针对 4D 毫米波雷达在 3D 目标检测中的两大核心缺陷：**点云稀疏性**和**方向角（DOA）估计误差**。

- **RHGM 模块**：利用图像语义引导，通过混合概率分布（高斯+均匀）生成密集的雷达点，并采用“独立编码”保护特征。
- **DSM 模块**：通过“空间同步”用雷达几何信息补足图像深度，通过“模态同步”根据光照条件动态分配模态权重。
- **性能**：在 VoD 数据集上 RoI AP 达到 88.28%，在 TJ4DRadSet 上也达到了 SOTA 水平。

------

## 2. 雷达混合生成模块 (RHGM) 

RHGM 的设计逻辑是：雷达点稀疏是因为检测阈值限制，方位不准是因为 DOA 算法在噪声下产生的峰值偏移。

### 2.1 前景提取与投影

首先利用变换矩阵将原始雷达点 $\mathcal{P}_{raw}$ 投影到图像平面，利用语义分割网络（Mask2former）获得掩码，落入掩码的点被标记为前景点 $\mathcal{P}_{fore}$ ，并获得语义特征 $s_i$ 。

### 2.2 混合概率密度函数 (Hybrid PDF)

为了生成新点，RHGM 定义了混合分布：

- **高斯分布区域**：在以前景点为中心、半径为 $r$ 的区域 $R_i(u,v)$ 内，模拟 DOA 误差的分布特性：

  $$
  f_{G}(u,v)=\frac{1}{2\pi b_{1}b_{2}}exp[-\frac{1}{2}(\frac{(u-u_{i})^{2}}{b_{1}^{2}}+\frac{(v-v_{i})^{2}}{b_{2}^{2}})]
  $$
  
- **均匀分布区域**：在掩码内但远离前景点的区域，因为缺乏先验信息，采用均匀分布：

  $$
  f_{U}(u,v)=\frac{1}{A}
  $$
  
- **混合采样公式**：

  $$
  f_{H}(u,v)=\begin{cases}f_{G}(u,v) & (u,v)\in R_{i}(u,v) \\ f_{U}(u,v) & (u,v)\in \complement_{R_{m}}R_{i}(u,v) \\ 0 & (u,v)\notin R_{m}\end{cases}
  $$

  - $R_m$ 是图像语义分割得到的**掩码区域**（比如图中整辆车的轮廓）。它是生成的边界，任何生成的点都不能跑出这个区域 。
  - $R_i(u,v)$  是以第 $i$ 个原始前景雷达点为中心、半径为 $r$ 像素的**圆形邻域** 。在这个圈子里，我们认为“附近有真实雷达信号”，所以用高斯分布 $f_G$ 来模拟 DOA（波达方向）误差导致的偏移 。
  - $\complement_{R_m}$ 表示在集合 $R_m$ 内部的**补集** 。就是在整辆车的掩码范围内，扣掉那些“靠近原始雷达点”的小圆圈后，剩下的**空白区域** 。

### 2.3 生成点合成与独立编码 (Separate Encoding)

采样得到的新像素点通过最近邻搜索继承最近前景点的深度和物理特征（速度、RCS），然后反向投影回 3D 空间。

为了防止不同属性的点（带语义特征与不带语义特征）在 Pillar 化过程中互相干扰，采用 **Separate Encoding**：

- **原始点**： $[x_i, y_i, z_i, f_i, 0_f, 0_s, c_i]$

- **生成点/前景点**： $[x_i, y_i, z_i, 0_f, f_i, s_i, c_i]$

  通过在不同的 slot 放置物理特征 $f_i$ 和语义特征 $s_i$ ，模型能有效区分点云来源。

------

## 3. 双重同步模块 (DSM) 详解

DSM 通过两步走战略，先解决“空间对齐”，再解决“环境鲁棒”。

### 3.1 空间同步 (Spatial Sync)

利用雷达的确定位置信息生成空间置信度掩码。

1. **空间模式预测**：利用空洞卷积扩大感受野，预测目标存在的概率图 $S_R$ ：

   $$
   S_{R}=\sigma(\text{Conv}(\text{AtrousConv}(F_{R})))
   $$

2. **显式监督**：使用 3D 边界框生成的 BEV 占据图通过 Focal Loss 对 $S_R$ 进行监督，引导模型学习真实的几何占据。

3. **图像增强**：将预测的掩码与图像特征 $F_I$ 点乘：

   $$
   F_{I}'=S_{R}'\otimes F_{I}
   $$

### 3.2 模态同步 (Modality Sync)

根据环境动态调整图像和雷达的分量权重。

1. **特征拼接与融合**：

   $$
   F_{concat} = \text{Conv}(F_{R} \oplus F_{I}')
   $$

2. **权重计算**：利用全局平均池化感知全局光照和环境状态，生成通道权重 $\mathcal{V}$ ：

   $$
   \mathcal{V} = \sigma(\text{Conv}(\text{AvgPooling}(F_{concat})))
   $$

3. **最终融合**：

   $$
   F = \mathcal{V}' \otimes F_{concat}
   $$

------

## 4. 实验分析与数据表

### 4.1 VoD 数据集 SOTA 对比 (Table 1)

| **方法**             | **模态** | **Car (RoI)** | **Pedestrian (RoI)** | **Cyclist (RoI)** | **mAP (RoI)** |
| -------------------- | -------- | ------------- | -------------------- | ----------------- | ------------- |
| PointPillars         | R        | 70.15         | 67.48                | 85.07             | 47.22         |
| RadarPillarNet       | R        | 71.65         | 65.86                | 86.19             | 43.10         |
| BEVFusion            | R+C      | 70.21         | 68.52                | 89.48             | 45.86         |
| LXL                  | R+C      | 72.18         | 72.93                | 88.31             | 72.93         |
| **HGSFusion (Ours)** | **R+C**  | **88.28**     | **87.49**            | **79.46**         | **62.61**     |

**分析**：HGSFusion 在汽车和行人检测上表现极其出色，RoI AP 分别提升至 88.28% 和 87.49%。但在骑行者（Cyclist）类别出现下滑，原因是 VoD 中存在大量与骑行者外观极度相似的“自行车架”和“未使用自行车”，导致 RHGM 生成了干扰特征。

### 4.2 模块消融实验 (Table 3)

| **ID** | **模态** | **RHGM** | **DSM** | **EAA AP** | **RoI AP** |
| ------ | -------- | -------- | ------- | ---------- | ---------- |
| 1      | R        | -        | -       | 47.70      | 66.88      |
| 2      | C        | -        | -       | 22.40      | 42.74      |
| 3      | R+C      | -        | -       | 54.82      | 73.27      |
| 4      | R+C      | √        | -       | 57.23      | 74.83      |
| 5      | R+C      | -        | √       | 55.99      | 74.45      |
| **6**  | **R+C**  | **√**    | **√**   | **58.96**  | **79.46**  |

**分析**：RHGM 对性能的提升（+1.56% RoI AP）证明了点云增广的有效性；DSM 的引入（+1.18% RoI AP）证明了同步机制的价值。两者结合实现了最大的增益（+6.19% RoI AP）。

### 4.3 点云编码策略对比 (Table 4)

| **编码策略**       | **缩写** | **EAA AP** | **RoI AP** |
| ------------------ | -------- | ---------- | ---------- |
| 直接拼接           | C.E.     | 56.22      | 74.46      |
| 逻辑区分 (One-hot) | D.E.     | 56.55      | 76.92      |
| **独立通道编码**   | **S.E.** | **58.96**  | **79.46**  |

**分析**：Separate Encoding (S.E.) 显著优于其他策略，证明在 Pillar 特征空间中通过物理维度隔离模态特征能更有效地保留原始信息和语义信息。

### 4.4 光照条件鲁棒性测试 (Table 5)

| **场景类型**    | **Base-R+C (3D mAP)** | **HGSFusion (3D mAP)** | **提升幅度** |
| --------------- | --------------------- | ---------------------- | ------------ |
| **Dark (暗光)** | 4.27                  | **15.68**              | **+11.41%**  |
| Normal (正常)   | 33.50                 | 35.82                  | +2.32%       |
| Shiny (强光)    | 22.37                 | 25.28                  | +2.91%       |

**分析**：在最极端黑暗场景下，HGSFusion 实现了 11.41% 的跨越式提升。这强有力地支持了 DSM 模块中模态同步的理论：在视觉失效时，模型能成功切换到以雷达为主的感知模式。

### 4.5 空间模式类型与监督消融 (Table 7)

| **模式类型** | **是否监督** | **EAA AP** | **RoI AP** |
| ------------ | ------------ | ---------- | ---------- |
| 3D           | ×            | 55.38      | 74.70      |
| 3D           | √            | 56.41      | 75.58      |
| 2D           | ×            | 57.28      | 78.77      |
| **2D**       | **√**        | **58.96**  | **79.46**  |

**分析**：2D 空间模式表现优于 3D。这是因为 4D 雷达高度角分辨率不足，3D 占据预测会引入噪声高度信息，而 2D 占据在 BEV 平面上更为精准。同时，显式监督比无监督提升了 0.69% 的 RoI AP。

------

## 5. 结论

HGSFusion 证明了**针对感知物理特性（DOA 误差）建模**的必要性。通过混合生成补偿了点云的“虚弱”，通过双重同步解决了模态间的“不信任”。实验数据显示，该模型在远距离（50-70m）和极低光照下的稳健性极强。
