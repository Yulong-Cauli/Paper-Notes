# RadarDistill

**出处会议：** CVPR 2024  
**是否开源：** 是，https://github.com/KAIST-AVLab/RadarDistill  
**关键词：** 知识蒸馏、雷达3D检测、跨模态对齐、LiDAR-Radar

---

​	目标：**利用 LiDAR（激光雷达）来教导 Radar（毫米波雷达），从而大幅提升 Radar 单独进行 3D 目标检测的性能。**

<div align="center"><img src="../assets/RadarDistill/_page_2_Figure_0.jpeg"></div>

---

## CMA (跨模态对齐) —— 先把“骨架”充实起来

​	试想一下这个场景： **LiDAR的特征图**：像一张填满了颜色的画，画面很丰富，物体的形状很完整；**Radar的特征图**：像一张白纸上撒了几粒沙子，绝大部分地方是空的，因为 Radar 点云太稀疏。

​	如果你直接计算这两个图的差异 Loss，比如做减法：
$$
Loss = (F_{LiDAR} - F_{Radar})^2
$$
​	LiDAR 在位置 A 有值，Radar 在位置 A 是 0（空的）。这时候强行让 Radar 去学位置 A 的值，Radar 会很懵，因为它那里根本没有原始数据支持，学起来非常困难且不稳定。

​	**CMA 的目的就是：让特征图先“胖”起来，在空间上填补空缺，这样才能和 LiDAR 的“画”对应上。**

​	CMA 的结构看起来像一个“梯子”或者“U型结构”。

<div align="center"><img src="../assets/RadarDistill/_page_3_Figure_13.jpeg"></div>

它主要干了三件事：**下采样、上采样、融合**。

**第一步：下采样（Down Block）—— 提取深层信息**

*   **输入**：Radar 的初始特征（比如分辨率是 $H \times W$）。
*   **操作**：使用 **DCN (可变形卷积)** 和 **ConvNeXt Block** 进行卷积和缩小尺寸。
*   **结果**：特征图尺寸变小（变成 $H/2 \times W/2$），但每个像素代表的“视野”变大了。这步是为了让那几个稀疏的点能感知到周围更大范围的信息。

**第二步：上采样（Up Block）—— 恢复尺寸并扩散特征**

*   **操作**：把刚才缩小的特征图再放大回去（使用转置卷积）。
*   **关键点**：在放大回去的过程中，原来那个稀疏的点，其特征信息会像水波一样**扩散**到周围的像素去。
    *   原来：只有一个点有值。
    *   现在：这个点周围的一圈都有值了。
*   **结果**：特征图变“密”了。

**第三步：聚合（Aggregation Module）**

*   **操作**：它不是简单的直上直下。你看图 3 中间那个带圆圈 **A** 的部分。它把“下采样过程中没处理前的特征”和“上采样回来的特征”**拼（Concatenate）在一起**，然后融合。
*   **为什么这么做？**
    *   这有点像 ResNet 的残差连接，或者是 UNet 的结构。
    *   它保证了 Radar 既保留了原始位置的精确信息（来自直接连接），又获得了扩散后的丰富背景信息（来自上下采样）。

### 小Trick

​	这里涉及到了深度学习里一个经典的 Trick，叫 **Deep Supervision（深层监督 / 中继监督）**。

​	你会发现 CMA 的结构像是一个“两层楼”的循环结构：**第 1 层处理**：原始 Radar 特征进来 -> 经过第一轮 Down/Up Block -> 得到中间结果 **$F_{rdr}^{(l_1)}$**。**第 2 层处理**：拿着第 1 层的结果 -> **再**经过一轮 Down/Up Block -> 得到最终结果 **$F_{rdr}^{(l_2)}$**。

​	**所以，** $l_1$ 是“半成品”，第一遍加工后的特征； $l_2$ 是“成品”，基于半成品，再加工一遍后的特征。 $l_2$ 肯定比 $l_1$ 更密、更丰富。

​	如果不加 $l_1$ 的监督，只看 $l_2$，那么，网络层数多了之后，梯度传导会变弱。你只在最后告诉学生“你没考好”，学生可能不知道是第 1 步做错了，还是第 2 步做错了。导致中间那个 $l_1$ 可能会“划水”，并没有学到好的特征，完全靠第 2 层硬撑。

​	为了防止网络中间层划水，强迫它每一层都努力向 LiDAR 靠拢，这样训练出来的模型**更稳、收敛更快**。

**这就像是老师改作文：**

*   **普通教学（只用 $l_2$）**：你写完终稿再给我看。
*   **AFD 的教学（同时用 $l_1, l_2$）**：你先写个初稿 ($l_1$) 给我看一眼，我给你挑挑错；然后你再润色成终稿 ($l_2$)，我再给你挑挑错。

---

## AFD (基于激活的特征蒸馏) —— 区分“该学”和“该闭嘴”

​	如果说 CMA 是为了让 Radar “长出肉来”，解决稀疏性，那么 **AFD 就是为了告诉 Radar “哪块肉该长，哪块肉不该长”，解决噪声和重点不突出的问题。**

Radar 的数据有两个大毛病：
1.  **有用的太少（Sparsity）**：真正的车、人反射回来的点很少。
2.  **没用的太多（Noise/Clutter）**：地面反射、栏杆反射等造成的“幽灵点”很多。

如果我们直接用简单的 MSE Loss（均方误差）让 Radar 全盘模仿 LiDAR：

*   **后果1**：因为背景区域（空地）面积巨大，Loss 会被背景主导，Radar 只要把背景学好（全预测为0），Loss 就会很低。结果就是 Radar **“躺平了”**，反正预测全是0也没大错，真正的物体反而学不到。
*   **后果2**：Radar 自身的噪声（比如地面反射出的假信号）如果不加抑制，Radar 会以为那是真东西，结果学出一堆误检。

**AFD 的核心策略就是：分而治之。**

AFD 把特征图上的每一个像素位置 $(i, j)$ 分成了两类区域：**AR (Active Regions)** 和 **IR (Inactive Regions)**。

#### 第一步：生成“激活掩码”（Mask）—— 谁说了算？
​	首先，我们要知道 LiDAR 和 Radar 分别觉得哪里有东西。
论文公式 (5) 定义了掩码 $M$：
$$
M_{mod,i,j}^{(l')} = \begin{cases} 1, & \text{if } F_{mod,i,j}^{(l')} > 0, \\ 0, & \text{otherwise,} \end{cases}
$$
​	如果某个位置的特征值 $>0$，就标记为 $1$，有东西，否则标记为 $0$，没东西。于是我们得到了两张地图：$M_{LiDAR}$ 和 $M_{Radar}$。

#### 第二步：划分势力范围（划重点！）
根据这两张地图，AFD 定义了两个关键区域（公式 6 和 7）：

1.  **AR (Active Regions，活跃区域)**：
    *   **公式**：$M_{Radar}=1$ 且 $M_{LiDAR}=1$
    *   **人话**：Radar 觉得这里有东西，LiDAR **也**觉得这里有东西。
    *   **判定**：这是**真家伙**（True Positive）。
    *   **策略**：Radar 你做得对！你要努力让你的特征数值无限接近 LiDAR 的数值。

2.  **IR (Inactive Regions，非活跃区域)**：
    *   **公式**：$M_{Radar}=1$ 且 $M_{LiDAR}=0$
    *   **人话**：Radar 觉得这里有东西，**但是** LiDAR 说“不，这里是空的”。
    *   **判定**：这是**幻觉/噪声**（False Positive）。
    *   **策略**：Radar 你错了！你要学会闭嘴，把这里的特征值压下去，模仿 LiDAR 的“0”。

*(注：论文这里没有特意定义“LiDAR=1 但 Radar=0”的区域，因为 AFD 主要是为了纠正 Radar 已有的激活特征。漏检的问题主要留给后面的 PFD 去解决。)*

---

### 3. AFD 的核心武器：自适应权重 (Adaptive Weighting)

这部分对应论文的 **公式 (8)**，这是 AFD 最精髓的地方。

$$
W_{sep,i,j}^{(l_n)} = \begin{cases} \alpha, & if(i,j) \in AR, \\ \rho \times \beta, & if(i,j) \in IR, \\ 0, & otherwise, \end{cases}
$$
这里为什么要搞这么复杂？是为了解决 **不平衡问题**。

*   **AR (真物体)** 的面积通常很小（大概只占 1%）。
*   **IR (误报/背景)** 的面积可能很大。

如果不加权重：IR 区域产生的 Loss 会淹没 AR 区域的 Loss。模型就会觉得：“消除噪声比检测物体更重要”。

**作者的做法：**
*   给 **AR** 区域一个固定的权重 $\alpha$（通常比较大）。
*   给 **IR** 区域一个权重 $\beta$，**并且**乘上了一个系数 $\rho$。
    *   $\rho$ 是什么？论文里写了 $\rho = N_{AR} / N_{IR}$（AR像素数除以IR像素数）。
    *   **妙处**：因为 $N_{AR}$ 很小，$N_{IR}$ 很大，所以 $\rho$ 是一个很小的数。
    *   **结果**：这相当于自动把 IR 区域的 Loss 权重**降低了**。

**一句话总结：**
AFD 就像是一个**“精准的去噪与增强过滤器”**。它拿着 LiDAR 的标准答案，先把 Radar 特征图上的噪声区域（IR）按下去，再把物体区域（AR）提上来，并且通过精细的权重调整，防止Radar“捡了芝麻丢了西瓜”。

这就解释了为什么 RadarDistill 能把假阳性（False Positives）压得那么低，同时还能提升检测率。

---

## PFD (基于建议框的特征蒸馏) —— 针对“考试结果”查漏补缺

首先，我们要把 Radar 的每一次“预测”分成三类。
*   **$H_{rdr}^{cls}$**：Radar 预测的热力图（分数越高，Radar 越觉得这里有车）。
*   **$H_{GT}^{cls}$**：标准答案的热力图（真实有车的地方是 1，其他是 0）。
*   **$\sigma$**：阈值（论文设为 0.1）。超过这个线就算“有”。

公式 **(11), (12), (13)** 就是三个过滤器：

**TP 真阳性 - 答对了** ：答案说有，Radar 也说有。后续要求**逼近**。你要学得更像一点。
$$
TP = (H_{GT}^{cls} > \sigma) \& (H_{rdr}^{cls} > \sigma)
$$
**FP 假阳性 - 瞎猜** ：答案说没有，Radar 非说有。后续要求**抑制**。Radar 你产生幻觉了，给我闭嘴。
$$
FP = (H_{GT}^{cls} < \sigma) \& (H_{rdr}^{cls} > \sigma)
$$
**FN  假阴性 - 漏检 ** ：答案说有，Radar 说没有。后续要求**唤醒**。这里明明有车，Radar 你给我把特征强度提上来！
$$
FN = (H_{GT}^{cls} > \sigma) \& (H_{rdr}^{cls} < \sigma)
$$
接着，我们要定权重，这是 **公式 (14)**，非常关键的一步。
$$
W_{proposal,i,j} = \begin{cases} \frac{\lambda_1}{N_{TP} + N_{FN}}, & if (i,j) \in (TP \cup FN) \\ \frac{\lambda_2}{N_{FP}}, & if (i,j) \in FP \\ 0, & otherwise \end{cases}
$$
这里面有两个细节：

1.  **分子 ($\lambda_1, \lambda_2$)**：这是人为设定的“重要性参数”。
    *   $\lambda_1$ 对应真实物体区域（TP+FN）。论文设为 **5**。
    *   $\lambda_2$ 对应误报区域（FP）。论文设为 **1**。
    *   **解读**：作者认为“把车找出来”比“消除误报”重要 5 倍。

2.  **分母 ($N_{TP}+N_{FN}, N_{FP}$)**：这是**区域面积（像素个数）**。
    *   为什么要除以面积？这叫**“平均化”**。
    *   如果不除以面积，如果 FP 区域（误报一大片）很大，它的 Loss 就会通过数量优势淹没 TP 区域（只是几个小点）的 Loss。
    *   **解读**：除以面积后，无论误报区域多大，它贡献的总 Loss 被限制住了，不会喧宾夺主。

---

### 第三步：变形（归一化）

$$
S_{mod,c,i,j}^{(h_m)} = \frac{\exp(F_{mod,c,i,j}^{(h_m)})}{\sum_{k=1}^{C} \exp(F_{mod,k,i,j}^{(h_m)})}
$$

*   **输入**：$F$ 是原始特征值（比如 LiDAR 是 50，Radar 是 5）。
*   **操作**：这就是标准的 **Softmax** 函数！
    *   注意求和符号 $\sum_{k=1}^{C}$，它是沿着 **Channel（通道）** 维度进行的。
*   **输出**：$S$ 是归一化后的概率分布（和为 1）。
*   **目的**：**抹平“嗓门”大小的差异，只比较“音调”准不准。**
    *   LiDAR 和 Radar 的绝对数值差异巨大，直接减会出问题。
    *   Softmax 后，大家都变成了 0 到 1 之间的概率分布，就可以公平比较了。

---

### 第四步：算总账（计算 Loss）

这是 **公式 (15)**，把上面准备好的东西全用上。

$$
L_{high}^{(m)} = \sum_{c,i,j} W_{proposal,i,j} \left| S_{ldr,c,i,j}^{(h_m)} - S_{rdr,c,i,j}^{(h_m)} \right|
$$
我们拆解一下这个公式：
1.  **$\left| S_{ldr} - S_{rdr} \right|$**：这是 **L1 Loss（绝对值误差）**。计算 LiDAR 和 Radar 在归一化后的特征分布差了多少。
2.  **$W_{proposal}$**：乘上第二步算出来的权重。
    *   如果是 TP/FN 区域，权重很大（乘以 5 再除以面积）。
    *   如果是 FP 区域，权重较小（乘以 1 再除以面积）。
    *   如果是背景，权重是 0（直接不让这项参与计算，Loss=0）。
3.  **$\sum$**：把所有像素、所有通道的误差加起来。

---

### 总结公式流

1.  **分类**：先看 Radar 哪答对了（TP）、哪答错了（FP）、哪没答（FN）。
2.  **定调**：把真实物体（TP+FN）的重要性设为 5，误报（FP）设为 1，并除以面积防刷屏。
3.  **拉齐**：用 Softmax 把 LiDAR 和 Radar 的特征数值拉到同一个起跑线（0-1）。
4.  **算分**：计算差距，乘上权重，加起来，就是最终的 PFD Loss。

这下这几个公式之间的逻辑链条是不是清晰了？

---

### 总结

这三个技术其实就是一套完整的**“名师辅导流程”**：

1.  **CMA**：先把学生的底子打好（把稀疏的点变成连贯的特征）。
2.  **AFD**：在学习过程中，告诉学生哪里是重点（学物体），哪里是干扰（去噪声）。
3.  **PFD**：在模拟考试后，针对答对、答错、漏答的题，分别进行针对性辅导。

## 损失函数

Radar 既然是一个目标检测器，它首先得**自己学会检测物体**，哪怕没有老师教，它也要能对着标准答案 Ground Truth 做题。

请看论文的 **公式 (18)**：

$$
L_{total} = \underbrace{L_{det}}_{\text{检测损失}} + \underbrace{\gamma L_{AFD}}_{\text{AFD蒸馏损失}} + \underbrace{\delta L_{PFD}}_{\text{PFD蒸馏损失}}
$$
这个公式由**三部分**组成：

1.  **$L_{det}$ (Detection Loss，基础检测损失)**：
    *   **这是什么？** 这是**Radar 学生自己做作业的得分**。
    *   即使没有 LiDAR 老师（没有蒸馏），Radar 网络自己也要输出框，也要和真实的标签（Ground Truth）去比对。
    *   这通常包括：分类损失（这到底是个车还是个柱子？）、回归损失（这个框中心在哪？长宽多少？）。
    *   **地位**：这是**主业**。如果这项没有，模型连最基本的检测都做不了。

2.  **$L_{AFD}$ (AFD Loss，低层特征蒸馏损失)**：
    *   **这是什么？** 这是**模仿 LiDAR 低层特征**的得分。
    *   **权重**：由参数 $\gamma$ 控制，论文里设为 5。
    *   **作用**：辅助项，帮 Radar 打好基础。

3.  **$L_{PFD}$ (PFD Loss，高层特征蒸馏损失)**：
    *   **这是什么？** 这是**模仿 LiDAR 高层特征**的得分。
    *   **权重**：由参数 $\delta$ 控制，论文里设为 25。注意这个权重很大！说明作者认为高层语义的模仿非常关键。
    *   **作用**：辅助项，帮 Radar 修正最终的理解。

**总结一下：**

总 Loss = **自己做题的 Loss** + **模仿老师低层特征的 Loss** + **模仿老师高层特征的 Loss**。

如果只用 $L_{AFD} + L_{PFD}$，那 Radar 就只会死记硬背老师的特征图，但忘了它的根本任务是画出正确的检测框（Ground Truth）。

所以正确的理解是：**“主线任务（检测） + 两条支线任务（蒸馏）”**。
