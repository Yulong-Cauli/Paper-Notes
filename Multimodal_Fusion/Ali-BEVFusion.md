# AIi-BEVFusion

**出处会议：** NeurIPS 2022  
**是否开源：** https://github.com/ADLab-AutoDrive/BEVFusion  
**关键词：** 多模态融合、BEV空间、动态融合模块、激光雷达-摄像头融合

---

### 1. 摄像头流 (Camera Stream)

为了摆脱对激光雷达点云的依赖，摄像头流独立地将多视图图像转换为 BEV 特征 1111。

+1



- **图像视图编码器 (Image-view Encoder)**：

  - 

    **2D 骨干网络**：采用 `CB-Swin-Tiny` 提取图像的基础深度特征 2222。

    +1

    

  - 

    **特征金字塔网络 (FPN) 与 ADP**：利用 FPN 处理多尺度特征，并加入自适应模块（ADP）通过自适应平均池化和 $1\times1$ 卷积来精炼上采样特征 3。

    

    

- **视图投影模块 (View Projector Module)**：

  - 该模块通过密集预测图像深度（以分类方式），结合相机外参，将 2D 图像特征投影到 3D 自车坐标系中 4444444。

    +2

    

  - 最终生成一个伪体素（Pseudo Voxel）张量 $V \in R^{X \times Y \times Z \times C}$ 5。

    

    

- **BEV 编码器模块 (BEV Encoder Module)**：

  - 

    **空间转通道 (S2C)**：为了降低计算成本并保留语义，它不使用池化或步长为 2 的 3D 卷积，而是通过 S2C 操作将 4D 张量重塑为 3D 张量 6。

    

    

  - 随后使用四个 $3\times3$ 卷积层逐渐降低通道维度，提取高层语义特征，得到摄像头 BEV 特征 $F_{Camera}$ 7。

    

    

### 2. 激光雷达流 (LiDAR Stream)

该流负责将原始点云转换为相同空间的 BEV 特征 $F_{LiDAR}$ 8。



- 

  **通用性**：该框架可以兼容多种主流的激光雷达检测网络，如 `PointPillars`、`CenterPoint` 和 `TransFusion` 9999。

  +1

  

- 

  **特征提取**：通过参数化体素化处理原始点云，并利用 3D 稀疏卷积骨干网络高效生成 BEV 空间特征 10。

  

  

### 3. 动态融合模块 (Dynamic Fusion Module)

这是将两路独立特征整合的关键步骤，采用了一种受 Squeeze-and-Excitation 机制启发的通道注意力模块 11111111。

+1



- 

  **特征拼接**：首先将 $F_{Camera}$ 和 $F_{LiDAR}$ 沿通道维度进行拼接 12。

  

  

- 

  **通道与空间融合 (CSF)**：通过一个 $3\times3$ 卷积层（静态融合函数 $f_{static}$ ）初步整合特征并降低维度 13131313。

  +1

  

- **自适应特征选择 (AFS)**：

  - 应用全局平均池化和 $1\times1$ 卷积（线性变换矩阵 $W$ ）计算权重，再通过 Sigmoid 函数激活 14141414。

    +2

    

  - 计算得到的权重与特征进行逐通道相乘，从而选择出最重要的融合特征 15151515。

    +1

    

  - 

    **融合公式**： $F_{fused} = f_{adaptive}(f_{static}([F_{Camera}, F_{LiDAR}]))$ 16。

    

    

### 4. 检测头与训练策略 (Detection Head & Training)

- 

  **预测头**：由于特征已统一在 BEV 空间，框架可以灵活挂载不同的检测头，包括基于锚点（Anchor-based）、无锚点（Anchor-free）以及基于 Transformer 的预测头 17171717。

  +1

  

- **两阶段训练方案**：

  1. 

     **第一阶段**：分别独立训练激光雷达流和摄像头流 18。

     

     

  2. 

     **第二阶段**：继承两个预训练流的权重，再进行 9 个 epoch 的联合融合训练 19。为了获得更好结果，该阶段还会加入 BEV 空间的增强技术 20。

     +1

     
